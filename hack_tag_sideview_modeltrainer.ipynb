{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hack_tag sideview",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1X1cvH2it9na"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os \n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from tqdm.notebook import tqdm\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "beXCZ5A9FdVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c state-farm-distracted-driver-detection"
      ],
      "metadata": {
        "id": "_ScjPiCPGdYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "mnzzBG6DIv-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/state-farm-distracted-driver-detection.zip"
      ],
      "metadata": {
        "id": "KAmFbldSKazq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train path\n",
        "train_path = \"/content/imgs/train\"\n",
        "# Test path\n",
        "test_path = \"/content/imgs/test\"\n",
        "\n",
        "train_length = 0\n",
        "for clas in os.listdir(train_path):\n",
        "    train_length += len(os.listdir(os.path.join(train_path, clas)))"
      ],
      "metadata": {
        "id": "HkcQQvoqvWkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Transforms and Augmentation\n",
        "train_transforms = T.Compose([ T.Resize((64, 64)),\n",
        "                               T.RandomAdjustSharpness(2),\n",
        "                               T.RandomRotation((-15, 15)),\n",
        "                               T.ColorJitter(brightness=.5, hue=.3),\n",
        "                               T.ToTensor(),\n",
        "                             ])\n",
        "\n",
        "# Loading Data using ImageFolder\n",
        "train_ds = ImageFolder(train_path, train_transforms)\n",
        "classes = train_ds.classes\n",
        "\n",
        "# Splitting into train-val set\n",
        "val_pct = .1\n",
        "val_size = int(val_pct * len(train_ds))\n",
        "train_ds ,valid_ds = random_split(train_ds, [len(train_ds)-val_size, val_size])\n",
        "\n",
        "# Data Loader\n",
        "batch_size = 64\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle = True, num_workers=2, pin_memory=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "OklFtDX-MJcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hlLVqOkJqp6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet34(nn.Module):\n",
        "    def __init__(self,num_classes,pretrained=True):\n",
        "        super().__init__()\n",
        "        # Use a pretrained model\n",
        "        self.network = models.resnet34(pretrained=pretrained)\n",
        "        # Replace last layer\n",
        "        self.network.fc = nn.Linear(self.network.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.network(x)"
      ],
      "metadata": {
        "id": "yFm8Zgj6M5bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# Model configuration\n",
        "pretrained_model = ResNet34(num_classes=10)\n",
        "\n",
        "pretrained_model.to(device)"
      ],
      "metadata": {
        "id": "1SY9ywMOM8P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting parameters\n",
        "epochs = 8\n",
        "lr = 1e-4\n",
        "opt_func = torch.optim.Adam"
      ],
      "metadata": {
        "id": "kViCetcRM-sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs,labels):\n",
        "  _,preds = torch.max(outputs,dim=1)\n",
        "  return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "        \n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    for batch in val_loader:\n",
        "        images,labels = batch\n",
        "        images = images.to(device)\n",
        "        print(images.shape)\n",
        "        labels = labels.to(device)\n",
        "        out = model(images)                     \n",
        "        loss = F.cross_entropy(out, labels)     \n",
        "        acc = accuracy(out, labels)             \n",
        "        outputs.append({\"val_loss\":loss.detach(), \"val_acc\":acc})\n",
        "        \n",
        "    batch_losses = [x[\"val_loss\"] for x in outputs]\n",
        "    epoch_loss = torch.stack(batch_losses).mean()     # Combine Losses\n",
        "    batch_accs = [x[\"val_acc\"] for x in outputs]\n",
        "    epoch_acc = torch.stack(batch_accs).mean()        # Combine Accuracies\n",
        "    return {\"val_loss\":epoch_loss.item(),\"val_acc\":epoch_acc.item()}"
      ],
      "metadata": {
        "id": "qgLcXbYGNc0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Training step\n",
        "\"\"\"\n",
        "#Set up custom optimizer with weight decay\n",
        "optimizer = opt_func(pretrained_model.parameters(), lr)\n",
        "\n",
        "# Saving results for the evaluation of the model and comperison with other model.\n",
        "history = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training Phase\n",
        "    pretrained_model.train()\n",
        "    train_losses = []\n",
        "    lrs = []\n",
        "    for batch in tqdm(train_dl):\n",
        "        images, labels = batch\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        out = pretrained_model(images)                    \n",
        "        loss = F.cross_entropy(out, labels)\n",
        "        train_losses.append(loss)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Validation Phase\n",
        "    result = evaluate(pretrained_model,valid_dl)\n",
        "    result[\"train_loss\"] = torch.stack(train_losses).mean().item()\n",
        "    # result2[\"lrs\"] = lrs  # I won't add learning rate changes to the history\n",
        "    print(\"Epoch [{}/{}], train_loss : {:.4f}, val_loss : {:.4f}], val_acc : {:.4f}\".format(epoch, epochs,\n",
        "                                                                                         result[\"train_loss\"],\n",
        "                                                                                         result[\"val_loss\"],\n",
        "                                                                                         result[\"val_acc\"]))\n",
        "    history.append(result)\n"
      ],
      "metadata": {
        "id": "7pzRnvvxNFJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(pretrained_model.state_dict(), \"/content/gdrive/MyDrive/Kaam/Hacktag_side_resnet34.pth\")\n",
        "torch.save(model, '/content/gdrive/MyDrive/Kaam/model.pth')\n"
      ],
      "metadata": {
        "id": "XsMJ6oGDVtDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = evaluate(pretrained_model,valid_dl)"
      ],
      "metadata": {
        "id": "dBiC50tMslhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FOQbwEXZsoft"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}